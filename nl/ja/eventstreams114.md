---

copyright:
  years: 2015, 2019
lastupdated: "2018-03-23"

keywords: IBM Event Streams, Kafka as a service, managed Apache Kafka

subcollection: eventstreams

---

{:new_window: target="_blank"}
{:shortdesc: .shortdesc}
{:screen: .screen}
{:codeblock: .codeblock}
{:pre: .pre}


# メッセージのコンシューム
{: #consuming_messages }

コンシューマーは、メッセージのストリームを Kafka トピックからコンシュームするアプリケーションです。 1 つのコンシューマーが 1 つ以上のトピックまたはパーティションにサブスクライブできます。 ここでは、Apache Kafka プロジェクトの一部である Java プログラミング・インターフェースについて重点的に説明します。 概念は他の言語にも当てはまりますが、名前は少し異なる場合があります。
{: shortdesc}

コンシューマーは Kafka に接続するときに初期ブートストラップ接続を行います。 この接続の接続先はクラスター内のどのサーバーでもかまいません。 コンシューマーは、コンシューム元にするトピックのパーティションおよびリーダーの情報を要求します。 その後、コンシューマーはパーティション・リーダーへの別の接続を確立し、メッセージのコンシュームを開始できるようになります。 これらのアクションは、コンシューマーが Kafka クラスターに接続すると、内部で自動的に発生します。

通常、コンシューマーは長時間実行アプリケーションです。 コンシューマーは、`Consumer.poll(...)` を定期的に呼び出すことによって、Kafka にメッセージを要求します。 コンシューマーは、`poll()` を呼び出し、メッセージのバッチを受け取り、それらをすぐに処理し、もう一度 `poll()` を呼び出します。

コンシューマーがメッセージを処理しても、そのメッセージはトピックから削除されません。 代わりに、コンシューマーは、どのメッセージが処理済みなのかを Kafka に知らせるいくつかの方法から選択できます。 この処理は、オフセットのコミットと呼ばれます。

プログラミング・インターフェースでは、メッセージは実際はレコードと呼ばれます。 例えば、Java クラス org.apache.kafka.clients.consumer.ConsumerRecord が、コンシューマー API のメッセージを表すために使用されます。 _レコード_ という用語と_メッセージ_ という用語は区別せずに使用できますが、レコードは基本的にはメッセージを表すために使用されます。

ここでの説明と合わせて {{site.data.keyword.messagehub}} での[メッセージのプロデュース](/docs/services/EventStreams?topic=eventstreams-producing_messages)も読むことをお勧めします。

## コンシューマー・プロパティーの構成 
{: #configuring_consumer_properties }

コンシューマーには、コンシューマーの動作の局面を制御する多数の構成設定があります。 最重要な設定のいくつかを以下に示します。

| 名前     |説明   | 有効な値   | デフォルト   |
|----------|---------|----------|---------|
|key.deserializer     | キーをデシリアライズするために使用されるクラス。 | Deserializer インターフェースを実装する Java クラス (例えば org.apache.kafka.common.serialization.StringDeserializer)  |デフォルトなし - 値を指定する必要があります|
|value.deserializer     | 値をデシリアライズするために使用されるクラス。 | Deserializer インターフェースを実装する Java クラス (例えば org.apache.kafka.common.serialization.StringDeserializer)  | デフォルトなし - 値を指定する必要があります |
|group.id | コンシューマーが所属するコンシューマー・グループの ID。 | ストリング |デフォルトなし|
|auto.offset.reset | コンシューマーに初期オフセットがないか、現行オフセットがクラスター内でもう使用可能でない場合の動作。 | latest、earliest、none | latest |
|enable.auto.commit | コンシューマーのオフセットを自動的にバックグラウンドでコミットするかどうかを決定します。 | true、false | true |
|auto.commit.interval.ms | オフセットの定期的コミットの間隔 (ミリ秒)。 | 0、... | 5000 (5 秒) |
|max.poll.records | poll() の 1 回の呼び出しで返される最大レコード数 | 1、... | 500 |
|session.timeout.ms | コンシューマーがコンシューマー・グループのメンバーであり続けるためにコンシューマー・ハートビートがその間に受信されなければならない時間 (ミリ秒)。 | 6000-300000 | 10000 (10 秒) |
|max.poll.interval.ms |コンシューマーがグループを抜ける前の最大ポーリング時間間隔。 | 1、... | 300000 (5 分) |
| | | | |

さらに多くの構成設定がありますが、それらを試してみる前に、必ず [Apache Kafka 資料 ![外部リンク・アイコン](../../icons/launch-glyph.svg "外部リンク・アイコン")](http://kafka.apache.org/documentation/){:new_window} を熟読してください。

## コンシューマー・グループ

_コンシューマー・グループ_ は、1 つ以上のトピックからのメッセージのコンシュームを協力して行うコンシューマーのグループです。 同じグループ内のすべてのコンシューマーは `group.id` 構成に同じ値を使用します。 作業負荷を処理するために複数のコンシューマーが必要な場合、同じコンシューマー・グループ内の複数のコンシューマーを実行できます。 必要なコンシューマーが 1 つのみであっても通常は `group.id` に値を指定します。

各コンシューマー・グループのクラスター内の 1 つのサーバーは_コーディネーター_ と呼ばれ、それがグループ内のコンシューマーへのパーティションの割り当てを担当します。 コーディネーターの責任は、負荷を平均化するためにクラスター内のすべてのサーバーで負います。 コンシューマーへのパーティションの割り当ては、グループのバランスが再調整されるたびに変化する可能性があります。

コンシューマー・グループにコンシューマーが加わると、そのコンシューマーはグループのコーディネーターを検出します。 次に、そのコンシューマーはグループに加わりたいことをコーディネーターに知らせます。そうすると、コーディネーターは新規メンバーも含めてグループ全体でパーティションのバランスの再調整を開始します。

コンシューマー・グループで以下のいずれかの変更があった場合、グループ・メンバーへのパーティションの割り当てを変更内容に合わせて変えることによって、グループでのバランスが再調整されます。

* グループにコンシューマーが加わる
* グループからコンシューマーが抜ける
* コンシューマーがコーディネーターによってもう稼働していないと見なされる
* 新規パーティションが既存トピックに追加される

コンシューマー・グループごとに、Kafka はコンシュームされる各パーティションのコミット済みオフセットを記憶します。

バランスが再調整されたコンシューマー・グループがある場合、そのグループを抜けたコンシューマーのコミットはグループに再加入するまでは拒否されることに注意してください。 この場合、コンシューマーはグループに再加入する必要があります。その際、以前にコンシューム元にしていたパーティションとは異なるパーティションが割り当てられる可能性があります。

## コンシューマーの活動性

Kafka は、障害が起こったコンシューマーを自動的に検出して、動作しているコンシューマーにパーティションを割り当て直します。 これを行うために、ポーリングとハートビートの 2 つのメカニズムが使用されます。

`Consumer.poll(...)` から返されたメッセージのバッチが大きいか、処理に時間がかかる場合、もう一度 `poll()` を呼び出すまでの遅延が顕著または予測不能になる可能性があります。 場合によっては、長い最大ポーリング間隔を構成して、メッセージ処理に時間がかかっているというだけの理由でコンシューマーがグループから削除されないようにする必要があります。 もしこれが唯一のメカニズムであったとすると、それは、障害が起こったコンシューマーの検出にかかる時間も長くなることを意味することになります。

コンシューマーの活動性をより簡単に処理できるようにするため、バックグラウンドでのハートビート処理が Kafka 0.10.1 で追加されました。 グループのコーディネーターは、グループ・メンバーがアクティブ状態のままであることを示すために定期的にハートビートを送信してくると予期しています。 コーディネーターに定期的にハートビートを送信するバックグラウンド・ハートビート・スレッドがコンシューマーで実行されます。 コーディネーターが_セッション・タイムアウト_ 内にグループ・メンバーからハートビートを受信しなかった場合、コーディネーターはそのメンバーをグループから削除し、グループのバランスの再調整を開始します。 メッセージ処理に長時間かかっている場合でも障害が起きたコンシューマーを短い時間で検出できるようにするため、セッション・タイムアウトを最大ポーリング間隔よりも大幅に短くすることができます。

最大ポーリング間隔は `max.poll.interval.ms` プロパティーを使用して構成でき、セッション・タイムアウトは `session.timeout.ms` プロパティーを使用して構成できます。 通常、メッセージの 1 つのバッチの処理にかかる時間が 5 分を超えない限り、これらの設定を使用する必要はありません。

## オフセットの管理

コンシューマー・グループごとに、Kafka はコンシュームされる各パーティションについてのコミット済みオフセットを保守します。 コンシューマーは、メッセージを処理してもパーティションからそのメッセージを削除しません。 代わりに、オフセットのコミットと呼ばれる処理を使用して、現行オフセットを更新するだけです。

{{site.data.keyword.messagehub}} は、コミット済みオフセットの情報を 7 日間保持します。

### 既存のコミット済みオフセットがない場合はどうなるか?
コンシューマーが開始され、コンシュームするパーティションが割り当てられると、そのコンシューマーは、所属するグループのコミット済みオフセットで開始します。 既存のコミット済みオフセットがない場合、コンシューマーは、以下に示すように、`auto.offset.reset` プロパティーの設定に基づいて、最初の使用可能なメッセージまたは最新の使用可能なメッセージのどちらで開始するのかを選択できます。

- `latest` (デフォルト)。 コンシューマーは、サブスクライブ後に到着するメッセージのみを受け取ってコンシュームします。 コンシューマーは、サブスクライブしたよりも前に送信されたメッセージについて何も知りません。したがって、トピックからのすべてのメッセージがコンシュームされることを期待しないでください。
- `earliest`。 コンシューマーは、送信済みのすべてのメッセージを認識するため、先頭からすべてのメッセージをコンシュームします。

コンシューマーで障害が起こったのが、あるメッセージを処理した後であるがオフセットをコミットする前である場合、コミット済みオフセットの情報はそのメッセージの処理を反映しません。 これは、パーティションに割り当てられる、同じグループ内の次のコンシューマーによって、そのメッセージが再び処理されることを意味します。

コミット済みオフセットが Kafka に保存されている場合、コンシューマーが再始動されると、コンシューマーは最後に停止したポイントから再開します。 コミット済みオフセットがある場合、`auto.offset.reset` プロパティーは使用されません。

### オフセットの自動コミット

オフセットをコミットする最も簡単な方法は、Kafka コンシューマーが自動的に行うようにすることです。 これは簡単な方法ですが、手動でのコミットよりも制御できることは少なくなります。 デフォルトでは、コンシューマーは 5 秒ごとに自動的にオフセットをコミットします。 このデフォルトのコミットは、コンシューマーによるメッセージ処理の進行状況とは無関係に、5 秒おきに発生します。 また、コンシューマーが `poll()` を呼び出す場合、これも、前の `poll()` 呼び出しから返された最新オフセットのコミットを引き起こします (それは処理済みである可能性が高いため)。

コミットされたオフセットがメッセージ処理を追い越している場合に、コンシューマーで障害が発生すると、一部のメッセージは処理されない可能性があります。 これは、処理はコミット済みオフセットで再び開始するが、そのオフセットは障害の前に処理された最後のメッセージよりも後であることが原因です。 この理由のため、一般的には、単純さよりも信頼性に重きが置かれる場合はオフセットを手動でコミットするのが最適です。

### オフセットの手動コミット

`enable.auto.commit` が `false` に設定されている場合、コンシューマーはオフセットを手動でコミットします。 これは同期的または非同期的に行うことができます。 最後に処理されたメッセージのオフセットを周期的タイマーに基づいてコミットするのが一般的なパターンです。 このパターンは、各メッセージが少なくとも一度は処理されるが、コミットされたオフセットが現在アクティブに進行しているメッセージの処理を追い越すことは決してないことを意味します。 周期的タイマーの頻度によって、コンシューマー障害の後に再処理される可能性のあるメッセージの数が制御されます。 アプリケーションが再始動された場合、またはグループのバランスが再調整された場合、最後に保存されたコミット済みオフセットからメッセージがもう一度取り出されます。

コミット済みオフセットは、処理が再開される開始点となるメッセージのオフセットです。 これは、通常、最後に処理されたメッセージのオフセットに* 1 を加算*したものです。

### コンシューマー・ラグ

パーティションのコンシューマー・ラグは、最後にパブリッシュされたメッセージのオフセットと、コンシューマーのコミット済みオフセットとの差です。 プロデュース速度とコンシューム速度には自然な変動があるのが一般的ですが、長時間にわたってコンシューム速度がプロデュース速度よりも遅くてはなりません。

あるコンシューマーでメッセージは正常に処理されているが、一群のメッセージを時々飛ばしているように見える場合、そのコンシューマーは遅れずについていけないというサインである可能性があります。 ログ圧縮を使用していないトピックの場合、定期的に古いログ・セグメントを削除することによってログ容量が管理されます。 あるコンシューマーが大幅に遅れていて、コンシュームしようとするメッセージが、削除されたログ・セグメント内にある場合、そのコンシューマーは次のログ・セグメントの先頭まで急にジャンプします。 コンシューマーがすべてのメッセージを処理することが重要である場合、このコンシューマーの観点からすると、この動作はメッセージを失うことを意味します。

<code>kafka-consumer-groups</code> ツールを使用して、コンシューマー・ラグを表示できます。 同じ目的のためにコンシューマー API およびコンシューマー・メトリックを使用することもできます。


## メッセージをコンシュームする速度の制御
{: #message_consumption_speed }

メッセージあふれが原因でメッセージ処理で問題がある場合、コンシューマー・オプションを設定して、メッセージをコンシュームする速度を制御することができます。 `fetch.max.bytes` および `max.poll.records` を使用して、1 回の `poll()` 呼び出しが返すことのできるデータ量を制御します。


## コンシューマーのバランス再調整の処理
グループに対するコンシューマーの追加または削除が行われると、グループのバランスが再調整され、コンシューマーはメッセージをコンシュームできません。 その結果として、コンシューマー・グループ内のすべてのコンシューマーが短時間使用不可になります。

「on partitions revoked」コールバックが通知されたときに手動でオフセットをコミットするため (自動コミットを使用していない場合)、および、「on partition assigned」コールバックを使用してバランス再調整が成功したことが通知されるまで処理を一時停止するために、ConsumerRebalanceListener を使用できます。


## コード・スニペット
{: #consumer_code_snippets notoc}

以下のコード・スニペットは、関係する概念を示すための概要レベルのものです。 完全な例については、{{site.data.keyword.messagehub}} サンプルを [GitHub ![外部リンク・アイコン](../../icons/launch-glyph.svg "外部リンク・アイコン")](https://github.com/ibm-messaging/event-streams-samples)で参照してください。

{{site.data.keyword.messagehub}} に接続するため、最初に構成プロパティーのセットを作成する必要があります。 {{site.data.keyword.messagehub}} へのすべての接続は、TLS およびユーザーとパスワードの認証を使用して保護されるため、最小限これらのプロパティーが必要です。 KAFKA_BROKERS_SASL、USER、および PASSWORD は、独自のサービス資格情報に置き換えてください。

```
Properties props = new Properties();
 props.put("bootstrap.servers", KAFKA_BROKERS_SASL);
 props.put("sasl.jaas.config", "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"USER\" password=\"PASSWORD\";");
 props.put("security.protocol", "SASL_SSL");
 props.put("sasl.mechanism", "PLAIN");
 props.put("ssl.protocol", "TLSv1.2");
 props.put("ssl.enabled.protocols", "TLSv1.2");
 props.put("ssl.endpoint.identification.algorithm", "HTTPS");
```

メッセージをコンシュームするため、以下の例のように、キーと値のデシリアライザーを指定する必要もあります。

```
 props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
 props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
```

次に、KafkaConsumer を使用してメッセージをコンシュームします。ここでは、各メッセージが 1 つの ConsumerRecord で表されます。 メッセージをコンシュームする最も一般的な方法は、グループ ID を設定することによってコンシューマーをコンシューマー・グループに入れ、次に、トピックのリストに対して `subscribe()` を呼び出すことです。 コンシューマーにはコンシュームするパーティションがいくつか割り当てられますが、トピック内のパーティションよりも多くのコンシューマーがグループにある場合は、コンシューマーにパーティションが割り当てられないこともあります。 次に、ループ内で `poll()` を呼び出して、処理するメッセージのバッチを受け取ります。それらのメッセージはそれぞれ 1 つの ConsumerRecord で表されます。

```
props.put("group.id", "G1");
Consumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Arrays.asList("T1"));
while (true) {
   ConsumerRecords<String, String> records = consumer.poll(100);
   for (ConsumerRecord<String, String> record : records)
     System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
}
```

このコンシューマー・ループは永久に実行されますが、`Consumer.wakeup()` を呼び出す別のスレッドから中断することで、きちんとシャットダウンできます。

オフセットを手動でコミットするには、最初に `enable.auto.commit` 構成を `false` に設定する必要があります。 次に、`Consumer.commmitSync()` または `Consumer.commitAsync()` のいずれかを使用して、コンシューマーのコミット済みオフセットを定期的に更新します。 単純にするため、この例では、各パーティションのレコードを処理し、最後のオフセットを別個にコミットしています。

```
props.put("group.id", "G1");
props.put("enable.auto.commit", "false");
Consumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Arrays.asList("T1"));
try {
  while (true) {
    ConsumerRecords<String, String> records = consumer.poll(100);
    for (TopicPartition tp : records.partitions()) {
      List<ConsumerRecord<String, String>> partRecords = records.records(tp);
      long lastOffset = 0;
      for (ConsumerRecord<String, String> record : partRecords) {
        System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
        lastOffset = record.offset();
      }

      consumer.commitSync(Collections.singletonMap(tp, new OffsetAndMetadata(lastOffset + 1)));
    }
  }
}
finally {
  consumer.close();
}
```

## 例外処理

Kafka クライアントを使用する堅固なアプリケーションは、特定の予期される状態の例外を処理する必要があります。 一部のメソッドは非同期であり、結果を `Future` またはコールバックを使用して返すため、例外が直接スローされないことがあります。 例が網羅されている [GitHub ![外部リンク・アイコン](../../icons/launch-glyph.svg "外部リンク・アイコン")](https://github.com/ibm-messaging/event-streams-samples) にコード例があります。

ユーザーのコードで処理する必要のある例外を以下にリストします。

### org.apache.kafka.common.errors.WakeupException
`Consumer.poll(...)` によって `Consumer.wakeup()` の呼び出しの結果としてスローされます。 これは、コンシューマーのポーリング・ループを中断するための標準的な方法です。 ポーリング・ループを終了し、`Consumer.close()` の呼び出しにより正常に切断する必要があります。
### org.apache.kafka.common.errors.NotLeaderForPartitionException
パーティションのリーダーが変わった場合に `Producer.send(...)` の結果としてスローされます。 クライアントは自動的にメタデータをリフレッシュして、最新のリーダー情報を検出します。 操作を再試行すると、更新後のメタデータを使用して正常に終了するはずです。
### org.apache.kafka.common.errors.CommitFailedException
リカバリー不能エラーが発生した場合に `Consumer.commitSync(...)` の結果としてスローされます。 場合によっては、単に操作を繰り返すことが不可能なことがあります。その理由は、パーティション割り当てが変わった可能性があり、コンシューマーがそれ自体のオフセットをコミットできなくなっている可能性があるためです。 `Consumer.commitSync(...)` は、1 回の呼び出しで複数のパーティションと共に使用されると、部分的に成功することがあるため、パーティションごとに別個の `Consumer.commitSync(...)` 呼び出しを使用することによってエラー・リカバリーを単純化できます。
### org.apache.kafka.common.errors.TimeoutException
メタデータを取得できない場合に `Producer.send(...),  Consumer.listTopics()` によってスローされます。 この例外は、要求された確認応答が `request.timeout.ms` 内に返されない場合、送信コールバック (または返される Future) でも発生します。 クライアントは操作を再試行できますが、反復された操作の効果は具体的な操作によって異なります。 例えば、メッセージ送信が再試行された場合は、メッセージが重複する可能性があります。

