---

copyright:
  years: 2015, 2018
lastupdated: "2018-06-23"

---

{:new_window: target="_blank"}
{:shortdesc: .shortdesc}
{:screen: .screen}
{:codeblock: .codeblock}
{:pre: .pre}

# メッセージのプロデュース
{: #producing_messages }


プロデューサーは、メッセージのストリームを Kafka トピックにパブリッシュするアプリケーションです。 ここでは、Apache Kafka プロジェクトの一部である Java プログラミング・インターフェースについて重点的に説明します。 概念は他の言語にも当てはまりますが、名前は少し異なる場合があります。

プログラミング・インターフェースでは、メッセージは実際はレコードと呼ばれます。 例えば、Java クラス org.apache.kafka.clients.producer.ProducerRecord が、プロデューサー API の観点からメッセージを表すために使用されます。 _レコード_ という用語と_メッセージ_ という用語は区別せずに使用できますが、レコードは基本的にはメッセージを表すために使用されます。

プロデューサーは Kafka に接続するときに初期ブートストラップ接続を行います。 この接続の接続先はクラスター内のどのサーバーでもかまいません。 プロデューサーは、パブリッシュ先にするトピックのパーティションおよびリーダーの情報を要求します。 その後、プロデューサーはパーティション・リーダーへの別の接続を確立し、メッセージのパブリッシュを開始できるようになります。 これらのアクションは、プロデューサーが Kafka クラスターに接続すると、内部で自動的に発生します。
 
パーティション・リーダーにメッセージが送信されても、そのメッセージはすぐにコンシューマーで使用可能にはなりません。 リーダーはメッセージのレコードをパーティションに付加し、その際、そのパーティションの次のオフセット数値をそのレコードに割り当てます。 同期レプリカのためのすべてのフォロワーがそのレコードを複製し、レコードをレプリカに書き込んだことを確認応答した後、レコードは*コミット済み* になり、コンシューマーで使用可能になります。

各メッセージが 1 つのレコードとして表され、レコードはキーと値の 2 つの部分からなります。 キーは一般的にメッセージに関するデータ用に使用され、値はメッセージ本体です。 Kafka エコシステム内の多くのツール (他のシステムへのコネクターなど) は、値のみを使用し、キーを無視します。そのため、メッセージ・データのすべてを値に入れ、パーティショニングまたはログ圧縮のためにのみキーを使用するのが最良です。 キーを使用するために Kafka から読み取りを行うものに依存してはなりません。

その他の多くのメッセージング・システムにも、他の情報をメッセージと共に受け渡す方法があります。 この目的のためのレコード・ヘッダーが、{{site.data.keyword.messagehub}} エンタープライズ・プランでサポートされる Kafka 0.11 で導入されました。 {{site.data.keyword.messagehub}} 標準プランは、現在は Kafka 0.10.2.1 に基づいているため、まだレコード・ヘッダーをサポートしていません。 

ここでの説明と合わせて {{site.data.keyword.messagehub}} での[メッセージのコンシューム](/docs/services/EventStreams/eventstreams114.html)も読むことをお勧めします。

## 構成設定
{: #config_settings}

プロデューサーには多くの構成設定があります。 プロデューサーのバッチ処理、再試行、メッセージ確認応答などの側面を制御することができます。 以下に、最重要な設定を示します。

| 名前     |説明   | 有効な値   | デフォルト   |
|----------|---------|----------|---------|
|key.serializer     | キーをシリアライズするために使用されるクラス。 | Serializer インターフェースを実装する Java クラス (例えば org.apache.kafka.common.serialization.StringSerializer) |デフォルトなし - 値を指定する必要があります|
|value.serializer     | 値をシリアライズするために使用されるクラス。 | Serializer インターフェースを実装する Java クラス (例えば org.apache.kafka.common.serialization.StringSerializer)  | デフォルトなし - 値を指定する必要があります |
|acks     | 各メッセージのパブリッシュに対して確認応答を行う必要があるサーバーの数。 これは、プロデューサーが必要とする耐久性保証を制御します。 | 0、1、all (または -1)  | 1 |
|retries     | 送信でエラーが発生したときにクライアントがメッセージを再送信する回数。 | 0、...  | 0 |
|max.block.ms     | 送信要求またはメタデータ要求が待機をブロックできる時間 (ミリ秒)。 | 0、...  | 60000 (1 分) |
|max.in.flight.requests.per.connection     | 1 つの接続でクライアントが送信する確認応答されていない要求が最大いくつになるとそれ以上の要求がブロックされるのかを示す数。| 1、...  | 5 |
|request.timeout.ms     | プロデューサーが要求への応答を待機する最大時間。 タイムアウト満了前に応答が受信されない場合、要求は再試行されるか、または、再試行回数に達している場合は失敗します。| 0、...  | 30000 (30 秒) |

さらに多くの構成設定がありますが、それらを試してみる前に、必ず [Apache Kafka 資料 ![外部リンク・アイコン](../../icons/launch-glyph.svg "外部リンク・アイコン")](http://kafka.apache.org/documentation/){:new_window} を熟読してください。

## パーティション化
{: #partitioning}

プロデューサーは、トピックにメッセージをパブリッシュするときに、どのパーティションを使用するのかを選択できます。 順序が重要な場合、パーティションはレコードの順序付きシーケンスであるが、1 つのトピックは 1 つ以上のパーティションからなる、という点に注意する必要があります。 一群のメッセージが順序通りに配信されるようにする必要がある場合、それらのメッセージが確実に同じパーティションに送信されるようにします。 これを行うための最も単純な方法は、それらのメッセージのすべてに同じキーを付与することです。 
 
プロデューサーは、メッセージをパブリッシュするときにパーティション番号を明示的に指定できます。 この方法は直接制御を可能にしますが、プロデューサーのコードはパーティション選択の管理について責任を担うため、より複雑になります。 詳しくは、Producer.partitionsFor メソッド呼び出しを参照してください。 例えば、[Kafka 0.11.0.1 ![外部リンク・アイコン](../../icons/launch-glyph.svg "外部リンク・アイコン")](https://kafka.apache.org/0110/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html){:new_window} でのこの呼び出しの説明があります。
 
プロデューサーがパーティション番号を指定しない場合、パーティションの選択はパーティショナーによって行われます。 Kafka プロデューサーに組み込まれたデフォルト・パーティショナーは、以下のように動作します。

* レコードにキーが付いていない場合、ラウンドロビン方式でパーティションを選択します。
* レコードにキーが付いている場合、そのキーのハッシュ値を計算してパーティションを選択します。 これは、同じキーを持つすべてのメッセージに対して同じパーティションを選択する効果があります。

ユーザー独自のカスタム・パーティショナーを作成することもできます。 カスタム・パーティショナーは、レコードをパーティションに割り当てる方式を任意に選択できます。 例えば、キー内の情報のサブセットのみを使用したり、アプリケーション固有の ID を使用したりできます。


## メッセージ順序付け
{: #message_ordering}

Kafka は、通常、プロデューサーによって送信された順序でメッセージを書き込みます。 ただし、再試行が原因で、メッセージが重複したり、並べ替えられたりする場合があります。 一連のメッセージが順序通りに送信されるようにする必要がある場合、それらすべてのメッセージが確実に同じパーティションに書き込まれるようにすることが重要です。
 
プロデューサーはメッセージ送信を自動的に再試行することもできます。 この再試行機能を有効にすることは多くの場合に有用です。代替手段ではアプリケーション・コード自体で再試行を実行しなければならないからです。 Kafka でのバッチ処理と自動再試行を組み合わせると、メッセージの重複および順序変更という結果が生じる可能性があります。
 
例えば、一連の 3 つのメッセージ &lt;M1、M2、M3&gt; を 1 つのトピックにパブリッシュするとします。 これらのレコードはすべて同じバッチ内に収まる可能性があるため、実際に一緒にパーティション・リーダーに送信されます。 リーダーは、それらをパーティションに書き込み、別々のレコードとして複製します。 障害が発生した場合、M1 と M2 はパーティションに追加されるが M3 はされないといったことが起こる可能性があります。 プロデューサーは、確認応答を受け取らないため、&lt;M1、M2、M3&gt; の送信を再試行します。 新規リーダーは、単に M1、M2、および M3 をパーティションに書き込みます。そうすると、パーティションには &lt;M1、M2、M1、M2、M3&gt; が含まれ、重複する M1 が元の M2 の後に続いている状態になります。 各ブローカーへの送信中の要求の数を 1 つのみに制限すると、このような順序の変更を防止できます。 それでも &lt;M1、M2、M2、M3&gt; のように単一レコードが重複することはあり得ますが、順序シーケンスが乱れることは決してありません。 Kafka 0.11 ({{site.data.keyword.messagehub}} ではまだ使用可能ではありません) では、べき等のプロデューサー機能を使用して M2 の重複を防止することもできます。
 
送信中の要求を 1 つのみに制限するとパフォーマンスへの影響が大きいため、時折起こるメッセージ重複を処理するようにアプリケーションを作成することが Kafka では通常の方法です。

## メッセージ確認応答
{: #message_acknowledgments}

メッセージをパブリッシュするときに、必要な確認応答のレベルを `acks` プロデューサー構成を使用して選択できます。 選択項目はスループットと信頼性の間のバランスを表しています。 次のように 3 つのレベルがあります。

<dl>
<dt>acks=0 (最も信頼性が低い)</dt>
<dd>メッセージは、ネットワークに書き込まれたらすぐに送信されたものと見なされます。 パーティション・リーダーからの確認応答はありません。 結果として、パーティション・リーダーが変わった場合、メッセージが失われる可能性があります。 このレベルの確認応答は、非常に高速ですが、場合によってはメッセージが失われる可能性があります。</dd>
<dt>acks=1 (デフォルト)</dt>
<dd>メッセージは、パーティション・リーダーがレコードを正常にパーティションに書き込んだらすぐにプロデューサーに対して確認応答されます。 確認応答はレコードが同期レプリカに到着したことが認知される前に発生するため、リーダーで障害が起こったがフォロワーがまだメッセージを持っていない場合にメッセージが失われる可能性があります。 パーティションのリーダーが変わった場合、古いリーダーはプロデューサーに通知し、プロデューサーはエラーを処理して、新しいリーダーへのメッセージ送信を再試行します。 メッセージはすべてのレプリカによって受信が確かめられる前に確認応答されるため、パーティションのリーダーが変わった場合、確認応答されたが、まだ完全には複製されていないメッセージは、失われる可能性があります。</dd>
<dt>acks=all (最も信頼性が高い)</dt>
<dd>メッセージは、パーティション・リーダーがレコードを正常にパーティションに書き込み、かつ、すべての同期レプリカが同じことを行ったら、プロデューサーに対して確認応答されます。 少なくとも 1 つの同期レプリカが使用可能であれば、パーティション・リーダーが変わってもメッセージは失われません。</dd>
</dl>

プロデューサーに対してメッセージが確認応答されるのを待たない場合でも、メッセージがコンシュームに使用可能になるのは、コミットされた場合のみであり、それは同期レプリカへの複製が完了していることを意味します。 言い換えると、プロデューサーの観点から見たメッセージ送信の待ち時間は、プロデューサーがメッセージ送信してからコンシューマーがそのメッセージを受け取るまでを測定したエンドツーエンドの待ち時間よりも短いということです。

可能な場合、メッセージの確認応答を待機してから次のメッセージをパブリッシュするのを避けてください。 待機すると、プロデューサーはメッセージをまとめるバッチ処理を行うことができず、メッセージをパブリッシュできる速度がネットワークの往復待ち時間を下回ることになります。

## バッチ処理、抑制、および圧縮
{: #batching}

効率性の目的のため、プロデューサーは、実際は、サーバーへ送信するために、レコードのバッチをまとめて収集します。 圧縮を有効にするとプロデューサーは各バッチを圧縮します。圧縮によって、ネットワークを介して転送する必要のあるデータ量が減り、パフォーマンスが向上する可能性があります。

サーバーへ送信できるよりも速くメッセージをパブリッシュしようとすると、プロデューサーは自動的にそれらをバッチ処理された要求のバッファーに入れます。 プロデューサーは、パーティションごとに未送信レコードのバッファーを保守します。 もちろん、ある時点からは、バッチ処理を行っても望む通りの速度に達することができなくなります。
 
影響を持つ別の要素もあります。 個々のプロデューサーまたはコンシューマーがクラスターを過負荷にするのを防止するため、{{site.data.keyword.messagehub}} はスループット割り当て量を適用します。 各プロデューサーがデータを送信する速度が計算され、割り当て量を超えようとしたプロデューサーは抑えられます。 この抑制は、プロデューサーへの応答の送信を少し遅らせることによって適用されます。 通常、これは単に自然なブレーキとして動作します。
 
要約すると、メッセージがパブリッシュされると、そのレコードはまずプロデューサーのバッファーに書き込まれます。 バックグラウンドでは、プロデューサーがレコードをバッチにまとめて、サーバーに送信します。 次に、サーバーはプロデューサーに応答しますが、プロデューサーがパブリッシュするのが速すぎる場合は、抑制のための遅延が適用されることがあります。 プロデューサーのバッファーが満杯になると、プロデューサーの送信呼び出しは遅延されますが、結局は例外で失敗する可能性があります。

## コード・スニペット
{: #code_snippets}

以下のコード・スニペットは、関係する概念を示すための概要レベルのものです。 完全な例については、Github で {{site.data.keyword.messagehub}} サンプルを参照してください (https://github.com/ibm-messaging/event-streams-samples)。

{{site.data.keyword.messagehub}} に接続するため、最初に構成プロパティーのセットを作成する必要があります。 {{site.data.keyword.messagehub}} へのすべての接続は、TLS およびユーザーとパスワードの認証を使用して保護されるため、最低限これらのプロパティーが必要です。 KAFKA_BROKERS_SASL、USER、および PASSWORD は、独自のサービス資格情報に置き換えてください。

```
Properties props = new Properties();
 props.put("bootstrap.servers", KAFKA_BROKERS_SASL);
 props.put("sasl.jaas.config", "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"USER\" password=\"PASSWORD\";");
 props.put("security.protocol", "SASL_SSL");
 props.put("sasl.mechanism", "PLAIN");
 props.put("ssl.protocol", "TLSv1.2");
 props.put("ssl.enabled.protocols", "TLSv1.2");
 props.put("ssl.endpoint.identification.algorithm", "HTTPS");
```

メッセージを送信するため、以下の例のように、キーと値のシリアライザーを指定する必要もあります。

```
 props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
 props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
```

次に、KafkaProducer を使用してメッセージを送信します。ここでは、各メッセージが 1 つの ProducerRecord で表されます。 終了したら KafkaProducer を閉じることを忘れないでください。 このコードは、メッセージを送信するだけであり、送信が成功したかどうかを調べるための待機はしていません。

```
 Producer<String, String> producer = new KafkaProducer<>(props);
 producer.send(new ProducerRecord<String, String>("T1", "key", "value"));
 producer.close();
 ```
 
`send()` メソッドは非同期であり、Future を返します。それを使用して完了を確認できます。

```
 Future<RecordMetadata> f = producer.send(new ProducerRecord<String, String>("T1", "key", "value"));
// Do some other stuff
// Now wait for the result of the send
 RecordMetadata rm = f.get();
 long offset = rm.offset; 
```

代替方法として、メッセージを送信するときにコールバックを指定できます。

```
producer.send(new ProducerRecord<String,String>("T1","key","value", new Callback() {
          public void onCompletion(RecordMetadata metadata, Exception exception) {
                     // This is called when the send completes, either successfully or with an exception
          }
});
```

詳しくは、包括的に記述されている [Kafka クライアントの Javadoc ![外部リンク・アイコン](../../icons/launch-glyph.svg "外部リンク・アイコン")](https://kafka.apache.org/0110/javadoc/index.html){:new_window} を参照してください。 

